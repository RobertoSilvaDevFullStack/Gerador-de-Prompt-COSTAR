from fastapi import FastAPI, HTTPException, status, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, Response
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import os
import json
from datetime import datetime, timedelta
import logging
from dotenv import load_dotenv
import time
import hashlib

# Caregar vari√°veis de ambiente
load_dotenv()

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Sistema de controle de quota para usu√°rios an√¥nimos
class AnonymousQuotaManager:
    def __init__(self):
        self.usage_file = 'data/anonymous_usage.json'
        self.daily_limit = 10  # Limite di√°rio para usu√°rios n√£o logados
        self.monthly_limit = 50  # Limite mensal para usu√°rios n√£o logados
        self._ensure_usage_file()
    
    def _ensure_usage_file(self):
        """Criar arquivo de uso an√¥nimo se n√£o existir"""
        os.makedirs('data', exist_ok=True)
        if not os.path.exists(self.usage_file):
            with open(self.usage_file, 'w') as f:
                json.dump({}, f)
    
    def _get_user_key(self, request: Request) -> str:
        """Gerar chave √∫nica baseada no IP e User-Agent"""
        client_ip = request.client.host
        user_agent = request.headers.get('user-agent', '')
        
        # Criar hash √∫nico mas que permita rastreamento por IP
        unique_string = f"{client_ip}_{user_agent[:50]}"
        return hashlib.sha256(unique_string.encode()).hexdigest()[:16]
    
    def _load_usage_data(self) -> Dict:
        """Carregar dados de uso"""
        try:
            with open(self.usage_file, 'r') as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            return {}
    
    def _save_usage_data(self, data: Dict):
        """Salvar dados de uso"""
        with open(self.usage_file, 'w') as f:
            json.dump(data, f, indent=2, default=str)
    
    def _clean_old_data(self, data: Dict) -> Dict:
        """Limpar dados antigos (mais de 30 dias)"""
        cutoff_date = datetime.now() - timedelta(days=30)
        cleaned_data = {}
        
        for user_key, user_data in data.items():
            if 'last_used' in user_data:
                try:
                    last_used = datetime.fromisoformat(user_data['last_used'])
                    if last_used > cutoff_date:
                        cleaned_data[user_key] = user_data
                except:
                    pass  # Ignorar dados corrompidos
        
        return cleaned_data
    
    def check_quota(self, request: Request) -> Dict[str, Any]:
        """Verificar se usu√°rio an√¥nimo pode fazer uma requisi√ß√£o"""
        user_key = self._get_user_key(request)
        data = self._load_usage_data()
        data = self._clean_old_data(data)
        
        now = datetime.now()
        today = now.strftime('%Y-%m-%d')
        this_month = now.strftime('%Y-%m')
        
        if user_key not in data:
            data[user_key] = {
                'daily_usage': {},
                'monthly_usage': {},
                'total_usage': 0,
                'first_used': now.isoformat(),
                'last_used': now.isoformat()
            }
        
        user_data = data[user_key]
        
        # Verificar uso di√°rio
        daily_count = user_data['daily_usage'].get(today, 0)
        monthly_count = user_data['monthly_usage'].get(this_month, 0)
        
        # Verificar limites
        if daily_count >= self.daily_limit:
            return {
                'allowed': False,
                'reason': 'Limite di√°rio excedido',
                'limit_type': 'daily',
                'used': daily_count,
                'limit': self.daily_limit,
                'reset_time': (now.replace(hour=23, minute=59, second=59) + timedelta(seconds=1)).isoformat(),
                'suggestion': 'Crie uma conta gratuita para aumentar seu limite!'
            }
        
        if monthly_count >= self.monthly_limit:
            return {
                'allowed': False,
                'reason': 'Limite mensal excedido',
                'limit_type': 'monthly',
                'used': monthly_count,
                'limit': self.monthly_limit,
                'reset_time': (now.replace(day=1, hour=0, minute=0, second=0) + timedelta(days=32)).replace(day=1).isoformat(),
                'suggestion': 'Crie uma conta gratuita para continuar usando!'
            }
        
        return {
            'allowed': True,
            'daily_remaining': self.daily_limit - daily_count,
            'monthly_remaining': self.monthly_limit - monthly_count,
            'daily_used': daily_count,
            'monthly_used': monthly_count
        }
    
    def increment_usage(self, request: Request) -> bool:
        """Incrementar uso do usu√°rio an√¥nimo"""
        user_key = self._get_user_key(request)
        data = self._load_usage_data()
        data = self._clean_old_data(data)
        
        now = datetime.now()
        today = now.strftime('%Y-%m-%d')
        this_month = now.strftime('%Y-%m')
        
        if user_key not in data:
            data[user_key] = {
                'daily_usage': {},
                'monthly_usage': {},
                'total_usage': 0,
                'first_used': now.isoformat(),
                'last_used': now.isoformat()
            }
        
        user_data = data[user_key]
        
        # Incrementar contadores
        user_data['daily_usage'][today] = user_data['daily_usage'].get(today, 0) + 1
        user_data['monthly_usage'][this_month] = user_data['monthly_usage'].get(this_month, 0) + 1
        user_data['total_usage'] += 1
        user_data['last_used'] = now.isoformat()
        
        # Limpar dados di√°rios antigos (manter apenas √∫ltimos 7 dias)
        cutoff_daily = (now - timedelta(days=7)).strftime('%Y-%m-%d')
        user_data['daily_usage'] = {
            date: count for date, count in user_data['daily_usage'].items()
            if date >= cutoff_daily
        }
        
        # Limpar dados mensais antigos (manter apenas √∫ltimos 3 meses)
        cutoff_monthly = (now - timedelta(days=90)).strftime('%Y-%m')
        user_data['monthly_usage'] = {
            month: count for month, count in user_data['monthly_usage'].items()
            if month >= cutoff_monthly
        }
        
        data[user_key] = user_data
        self._save_usage_data(data)
        return True

# Instanciar gerenciador de quota an√¥nima
anonymous_quota = AnonymousQuotaManager()

# Inicializar FastAPI
app = FastAPI(
    title="COSTAR Prompt Generator API - Demo Mode",
    description="API para gera√ß√£o e gerenciamento de prompts estruturados COSTAR (Modo Demonstra√ß√£o)",
    version="1.0.0-demo"
)

# Configurar CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Endpoint raiz
@app.get("/")
async def root():
    """Servir a p√°gina principal do frontend"""
    try:
        with open("static/index.html", "r", encoding="utf-8") as f:
            html_content = f.read()
        return HTMLResponse(html_content)
    except FileNotFoundError:
        logger.error("‚ùå Arquivo index.html n√£o encontrado!")
        return HTMLResponse("""
        <html>
            <head><title>COSTAR Prompt Generator</title></head>
            <body>
                <h1>üéØ COSTAR Prompt Generator</h1>
                <p>üìÅ Frontend n√£o encontrado. Servindo p√°gina b√°sica.</p>
                <p><a href="/static/debug-login-main.html">ÔøΩ Debug Login</a></p>
                <p><a href="/docs">üìö API Docs</a></p>
            </body>
        </html>
        """)

# Endpoint de healthcheck para Railway
@app.get("/status")
async def health_check():
    """Endpoint de healthcheck para Railway e outros servi√ßos"""
    return {
        "status": "healthy",
        "service": "COSTAR Prompt Generator",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0-demo"
    }

# Endpoint de debug para verificar arquivos (remover em produ√ß√£o)
@app.get("/debug/files")
async def debug_files():
    """Debug: verificar estrutura de arquivos"""
    import os
    files_info = {
        "current_dir": os.getcwd(),
        "frontend_exists": os.path.exists("static"),
        "index_exists": os.path.exists("static/index.html"),
        "frontend_files": []
    }
    
    if os.path.exists("static"):
        try:
            files_info["frontend_files"] = os.listdir("static")[:10]  # Apenas primeiros 10
        except:
            files_info["frontend_files"] = ["erro ao listar"]
    
    return files_info

# Endpoint de debug para testar IAs
@app.get("/debug/ai")
async def debug_ai():
    """Debug: testar provedores de IA"""
    try:
        logger.info("üîç Debug AI endpoint chamado")
        
        # Verificar vari√°veis de ambiente primeiro
        env_check = {
            "GROQ_API_KEY": "‚úÖ" if os.getenv("GROQ_API_KEY") else "‚ùå",
            "GEMINI_API_KEY": "‚úÖ" if os.getenv("GEMINI_API_KEY") else "‚ùå",
            "TOGETHER_API_KEY": "‚úÖ" if os.getenv("TOGETHER_API_KEY") else "‚ùå"
        }
        
        logger.info(f"üìã Environment check: {env_check}")
        
        # Tentar importar o servi√ßo
        try:
            from app.services.production_multi_ai import get_multi_ai_service
            service = get_multi_ai_service()
            
            providers_info = {
                "providers_loaded": len(service.providers),
                "available_providers": list(service.providers.keys()),
            }
            
            logger.info(f"ü§ñ Providers info: {providers_info}")
            
            # Teste simples sem chamar APIs externas
            return {
                "status": "debug_success",
                "environment_vars": env_check,
                **providers_info,
                "note": "Teste b√°sico sem chamadas de API"
            }
            
        except Exception as import_error:
            logger.error(f"‚ùå Erro ao importar service: {str(import_error)}")
            return {
                "status": "import_error",
                "error": str(import_error),
                "environment_vars": env_check
            }
            
    except Exception as e:
        logger.error(f"‚ùå Erro geral no debug: {str(e)}")
        return {
            "status": "general_error",
            "error": str(e),
            "environment_vars": {
                "GROQ_API_KEY": "‚úÖ" if os.getenv("GROQ_API_KEY") else "‚ùå",
                "GEMINI_API_KEY": "‚úÖ" if os.getenv("GEMINI_API_KEY") else "‚ùå",
                "TOGETHER_API_KEY": "‚úÖ" if os.getenv("TOGETHER_API_KEY") else "‚ùå"
            }
        }

# Endpoint root
@app.get("/", response_class=HTMLResponse)
async def root():
    """Servir a p√°gina principal do frontend"""
    try:
        with open("static/index.html", "r", encoding="utf-8") as f:
            html_content = f.read()
        return HTMLResponse(content=html_content)
    except FileNotFoundError:
        return HTMLResponse(content="""
        <!DOCTYPE html>
        <html lang="pt-BR">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>COSTAR Prompt Generator</title>
        </head>
        <body>
            <h1>üöÄ COSTAR Prompt Generator</h1>
            <p>‚úÖ API est√° funcionando!</p>
            <p>üìÅ Frontend n√£o encontrado. Servindo p√°gina b√°sica.</p>
            <p><a href="/docs">üìö Documenta√ß√£o da API</a></p>
            <p><a href="/status">‚ù§Ô∏è Status da Aplica√ß√£o</a></p>
        </body>
        </html>
        """)

# Endpoint de API info (para manter compatibilidade)
@app.get("/api")
async def api_info():
    """Informa√ß√µes da API"""
    return {
        "message": "COSTAR Prompt Generator API est√° funcionando!",
        "status": "online",
        "docs": "/docs",
        "health": "/status"
    }

# Servir arquivos est√°ticos
app.mount("/static", StaticFiles(directory="static"), name="static")
app.mount("/frontend", StaticFiles(directory="static"), name="frontend")

# Tentar importar e incluir as rotas de membros e admin
try:
    from app.routes.member_admin_routes import member_router, admin_router
    app.include_router(member_router)
    app.include_router(admin_router)
    logger.info("‚úÖ Rotas de membros e admin carregadas com sucesso")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel carregar rotas de membros/admin: {e}")
except Exception as e:
    logger.error(f"‚ùå Erro ao carregar rotas de membros/admin: {e}")

# Importar servi√ßo de analytics para logging
try:
    from app.services.admin_analytics_service import AdminAnalyticsService
    analytics_service = AdminAnalyticsService()
    logger.info("‚úÖ Servi√ßo de analytics carregado com sucesso")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel carregar servi√ßo de analytics: {e}")
    analytics_service = None
except Exception as e:
    logger.error(f"‚ùå Erro ao carregar servi√ßo de analytics: {e}")
    analytics_service = None

# Tentar importar e incluir as rotas de status
try:
    from app.routes.status_routes import router as status_router
    app.include_router(status_router)
    logger.info("‚úÖ Rotas de status carregadas com sucesso")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel carregar rotas de status: {e}")
except Exception as e:
    logger.error(f"‚ùå Erro ao carregar rotas de status: {e}")

# Verificar servi√ßos dispon√≠veis
supabase_enabled = bool(os.getenv("SUPABASE_URL") and os.getenv("SUPABASE_ANON_KEY") and 
                       os.getenv("SUPABASE_URL") != "your_supabase_url_here" and
                       os.getenv("SUPABASE_ANON_KEY") != "your_supabase_anon_key_here")

# Verificar disponibilidade de m√∫ltiplas IAs
ai_keys = {
    "gemini": os.getenv("GEMINI_API_KEY", ""),
    "groq": os.getenv("GROQ_API_KEY", ""),
    "huggingface": os.getenv("HUGGINGFACE_API_KEY", ""),
    "cohere": os.getenv("COHERE_API_KEY", ""),
    "together": os.getenv("TOGETHER_API_KEY", "")
}

# Verificar se pelo menos uma IA est√° configurada
ai_enabled = any(
    key and key != f"your_{name}_api_key_here" and len(key) > 10
    for name, key in ai_keys.items()
)

# Log detalhado da verifica√ß√£o de AIs
logger.info("üîç [STARTUP] Verificando configura√ß√£o das IAs:")
for name, key in ai_keys.items():
    if key and len(key) > 10:
        logger.info(f"‚úÖ [STARTUP] {name.upper()}: configurada ({len(key)} chars)")
    else:
        logger.info(f"‚ùå [STARTUP] {name.upper()}: n√£o configurada")

logger.info(f"üéØ [STARTUP] AI_ENABLED = {ai_enabled}")

# Manter compatibilidade com c√≥digo legado
gemini_enabled = ai_enabled

# Modelos Pydantic
class PromptData(BaseModel):
    contexto: str
    objetivo: str
    estilo: str
    tom: str
    audiencia: str
    resposta: str

class PromptCreate(BaseModel):
    titulo: str
    prompt_data: PromptData
    categoria: str = "geral"
    tags: List[str] = []
    favorito: bool = False
    compartilhado: bool = False

class GeminiRequest(BaseModel):
    prompt: str
    temperatura: float = 0.7
    max_tokens: int = 2048

# Armazenamento em mem√≥ria para demo
demo_prompts = []
demo_user = {
    "id": "demo-user-123",
    "email": "demo@exemplo.com", 
    "nome": "Usu√°rio Demo"
}

# Rotas principais
@app.get("/api/health")
async def health_check():
    """Verifica√ß√£o de sa√∫de da API"""
    return {
        "status": "ok - demo mode",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0-demo",
        "services": {
            "supabase": "available" if supabase_enabled else "demo mode",
            "gemini": "available" if gemini_enabled else "demo mode",
            "redis": "demo mode"
        }
    }

@app.post("/api/prompts/preview")
async def preview_prompt(prompt_data: PromptData, request: Request):
    """Gerar preview do prompt COSTAR (modo demo com quota)"""
    try:
        logger.info(f"üéØ [PREVIEW] Recebendo requisi√ß√£o de preview")
        logger.info(f"üìã [PREVIEW] Dados: contexto={prompt_data.contexto[:30]}..., objetivo={prompt_data.objetivo[:30]}...")
        logger.info(f"üîç [PREVIEW] AI_ENABLED = {ai_enabled}")
        
        # Verificar se √© usu√°rio autenticado
        auth_header = request.headers.get('authorization')
        is_authenticated = bool(auth_header and auth_header.startswith('Bearer '))
        
        if not is_authenticated:
            # Para usu√°rios n√£o logados, verificar quota
            quota_check = anonymous_quota.check_quota(request)
            
            if not quota_check['allowed']:
                logger.warning(f"üö´ [PREVIEW] Quota excedida para usu√°rio an√¥nimo: {quota_check['reason']}")
                raise HTTPException(
                    status_code=status.HTTP_429_TOO_MANY_REQUESTS,
                    detail={
                        "message": quota_check['reason'],
                        "limit_info": {
                            "limit_type": quota_check['limit_type'],
                            "used": quota_check['used'],
                            "limit": quota_check['limit'],
                            "reset_time": quota_check['reset_time'],
                            "suggestion": quota_check['suggestion']
                        }
                    }
                )
            
            logger.info(f"‚úÖ [PREVIEW] Quota OK para an√¥nimo - Di√°rio: {quota_check['daily_remaining']}, Mensal: {quota_check['monthly_remaining']}")
        
        # Gerar prompt COSTAR com m√∫ltiplas IAs
        if ai_enabled:
            logger.info("ü§ñ [PREVIEW] AI habilitada, iniciando processo de IA")
            # Usar sistema de m√∫ltiplas IAs (vers√£o produ√ß√£o)
            try:
                logger.info("üì¶ [PREVIEW] Importando get_multi_ai_service...")
                from app.services.production_multi_ai import get_multi_ai_service
                
                logger.info("üöÄ [PREVIEW] Obtendo inst√¢ncia do servi√ßo...")
                service = get_multi_ai_service()
                
                logger.info(f"‚úÖ [PREVIEW] Servi√ßo obtido. Provedores: {len(service.providers)}")
                logger.info(f"üìã [PREVIEW] Provedores dispon√≠veis: {list(service.providers.keys())}")
                
                # Usar timeout para evitar travamento
                import asyncio
                logger.info("‚è∞ [PREVIEW] Iniciando gera√ß√£o com timeout de 30s...")
                
                prompt_aprimorado = await asyncio.wait_for(
                    generate_costar_prompt_with_multi_ai(prompt_data, service),
                    timeout=30.0  # 30 segundos de timeout
                )
                logger.info(f"‚úÖ [PREVIEW] Prompt gerado com IA: {len(prompt_aprimorado)} caracteres")
                logger.info(f"üé® [PREVIEW] Preview do resultado: {prompt_aprimorado[:100]}...")
                
            except asyncio.TimeoutError:
                logger.warning("‚è∞ [PREVIEW] TIMEOUT na gera√ß√£o com AI (30s), usando fallback")
                prompt_aprimorado = generate_costar_prompt_basic(prompt_data)
            except ImportError as e:
                logger.warning(f"‚ö†Ô∏è [PREVIEW] ERRO importando ProductionMultiAI: {e}")
                # Fallback para vers√£o original
                try:
                    logger.info("üîÑ [PREVIEW] Tentando MultiAIService original...")
                    from app.services.multi_ai_service import MultiAIService
                    multi_ai_service = MultiAIService()
                    prompt_aprimorado = await generate_costar_prompt_with_multi_ai(prompt_data, multi_ai_service)
                except Exception as fallback_error:
                    logger.error(f"‚ùå [PREVIEW] Fallback MultiAIService falhou: {fallback_error}")
                    prompt_aprimorado = generate_costar_prompt_basic(prompt_data)
            except Exception as e:
                logger.error(f"‚ùå [PREVIEW] ERRO na gera√ß√£o com AI: {str(e)}")
                logger.error(f"üîß [PREVIEW] Tipo do erro: {type(e).__name__}")
                # Fallback para modo b√°sico
                prompt_aprimorado = generate_costar_prompt_basic(prompt_data)
                logger.info("üîÑ [PREVIEW] Usando modo b√°sico como fallback")
        else:
            logger.info("üîß [PREVIEW] AI DESABILITADA, usando gera√ß√£o b√°sica")
            # Usar gera√ß√£o b√°sica sem IA
            prompt_aprimorado = generate_costar_prompt_basic(prompt_data)
        
        # Incrementar uso se n√£o autenticado
        if not is_authenticated:
            anonymous_quota.increment_usage(request)
            logger.info("üìä [PREVIEW] Uso incrementado para usu√°rio an√¥nimo")
        
        # Determinar modo baseado no conte√∫do do prompt
        modo = "B√°sico (sem IA)"
        if ai_enabled:
            # Verificar se tem estrutura COSTAR completa (formato espec√≠fico)
            costar_patterns = [
                "**Context (Contexto)**", "**Objective (Objetivo)**", "**Style (Estilo)**",
                "**Tone (Tom)**", "**Audience (Audi√™ncia)**", "**Response (Formato de Resposta)**"
            ]
            
            # Contar quantas se√ß√µes COSTAR est√£o presentes
            costar_sections_found = sum(1 for pattern in costar_patterns if pattern in prompt_aprimorado)
            
            # Verificar varia√ß√µes alternativas
            alternative_patterns = [
                "**CONTEXTO**", "**OBJETIVO**", "**ESTILO**",
                "**TOM**", "**AUDI√äNCIA**", "**RESPOSTA**"
            ]
            alt_sections_found = sum(1 for pattern in alternative_patterns if pattern in prompt_aprimorado)
            
            total_sections = max(costar_sections_found, alt_sections_found)
            
            if total_sections >= 4 and len(prompt_aprimorado) > 800:
                modo = "Multi-AI aprimorado"
            elif total_sections >= 3 and len(prompt_aprimorado) > 600:
                modo = "Multi-AI processado"
            elif "fallback inteligente" in prompt_aprimorado.lower():
                modo = "Multi-AI (HuggingFace)"
            elif len(prompt_aprimorado) > 400:
                modo = "AI processado"
            elif "fallback" in prompt_aprimorado.lower():
                modo = "Fallback b√°sico"
        
        # Incluir informa√ß√µes de quota na resposta se n√£o autenticado
        response_data = {
            "message": "Preview gerado com sucesso (modo demo)",
            "prompt_original": {
                "contexto": prompt_data.contexto,
                "objetivo": prompt_data.objetivo,
                "estilo": prompt_data.estilo,
                "tom": prompt_data.tom,
                "audiencia": prompt_data.audiencia,
                "resposta": prompt_data.resposta
            },
            "prompt_aprimorado": prompt_aprimorado,
            "timestamp": datetime.now().isoformat(),
            "modo": modo
        }
        
        # Adicionar informa√ß√µes de quota para usu√°rios n√£o autenticados
        if not is_authenticated:
            quota_info = anonymous_quota.check_quota(request)
            response_data["quota_info"] = {
                "daily_remaining": quota_info.get('daily_remaining', 0),
                "monthly_remaining": quota_info.get('monthly_remaining', 0),
                "daily_used": quota_info.get('daily_used', 0),
                "monthly_used": quota_info.get('monthly_used', 0),
                "daily_limit": anonymous_quota.daily_limit,
                "monthly_limit": anonymous_quota.monthly_limit,
                "suggestion": "Crie uma conta gratuita para aumentar seus limites!"
            }
        
        return response_data
        
    except Exception as e:
        logger.error(f"Erro ao gerar preview do prompt: {e}")
        # Fallback para vers√£o b√°sica
        prompt_basico = generate_costar_prompt_basic(prompt_data)
        return {
            "message": "Preview gerado com sucesso (modo b√°sico)",
            "prompt_original": prompt_data.dict(),
            "prompt_aprimorado": prompt_basico,
            "timestamp": datetime.now().isoformat(),
            "modo": "B√°sico (fallback)"
        }

@app.get("/api/quota/anonymous")
async def check_anonymous_quota(request: Request):
    """Verificar quota de usu√°rio an√¥nimo"""
    quota_info = anonymous_quota.check_quota(request)
    return {
        "allowed": quota_info["allowed"],
        "daily_remaining": quota_info.get("daily_remaining", 0),
        "monthly_remaining": quota_info.get("monthly_remaining", 0),
        "daily_used": quota_info.get("daily_used", 0),
        "monthly_used": quota_info.get("monthly_used", 0),
        "daily_limit": anonymous_quota.daily_limit,
        "monthly_limit": anonymous_quota.monthly_limit,
        "limits": {
            "daily": anonymous_quota.daily_limit,
            "monthly": anonymous_quota.monthly_limit
        },
        "message": "Quota para usu√°rio an√¥nimo",
        "suggestion": "Crie uma conta gratuita para aumentar seus limites!"
    }

@app.post("/api/prompts/analyze")  
async def analyze_prompt_quality(prompt_data: PromptData):
    """Analisar qualidade do prompt COSTAR usando Multi-AI"""
    try:
        # Usar Multi-AI Service (vers√£o produ√ß√£o)
        multi_ai_service = None
        try:
            from app.services.production_multi_ai import get_multi_ai_service
            multi_ai_service = get_multi_ai_service()
            logger.info("ü§ñ [ANALYZE] Usando ProductionMultiAIService")
        except ImportError:
            logger.info("üîÑ [ANALYZE] Fallback para MultiAIService original")
            from app.services.multi_ai_service import MultiAIService
            multi_ai_service = MultiAIService()
            await multi_ai_service.initialize()
        
        # Gerar prompt primeiro usando Multi-AI
        prompt_aprimorado = await generate_costar_prompt_with_multi_ai(prompt_data, multi_ai_service)
        
        # Criar prompt para an√°lise de qualidade
        analysis_prompt = f"""
Analise a qualidade deste prompt COSTAR e forne√ßa uma avalia√ß√£o estruturada:

{prompt_aprimorado}

Forne√ßa sua an√°lise no seguinte formato JSON:
{{
  "pontuacao": [n√∫mero de 0 a 100],
  "qualidade": "[Excelente/Boa/Regular/Ruim]",
  "resumo": "[breve resumo da an√°lise]",
  "pontos_fortes": ["ponto1", "ponto2"],
  "sugestoes": ["sugest√£o1", "sugest√£o2"],
  "metricas_detalhadas": {{
    "completude": [0-100],
    "especificidade": [0-100], 
    "coerencia": [0-100],
    "acionabilidade": [0-100]
  }}
}}
"""
        
        # Gerar an√°lise usando Multi-AI
        analysis_response = await multi_ai_service.generate_content(analysis_prompt)
        
        # Tentar parsear JSON da resposta
        try:
            import json
            # Extrair JSON da resposta (pode vir com texto extra)
            json_start = analysis_response.find('{')
            json_end = analysis_response.rfind('}') + 1
            if json_start >= 0 and json_end > json_start:
                json_text = analysis_response[json_start:json_end]
                analise = json.loads(json_text)
            else:
                raise ValueError("JSON n√£o encontrado na resposta")
        except:
            # Fallback para an√°lise b√°sica se n√£o conseguir parsear
            analise = generate_basic_analysis(prompt_data)
        
        return {
            "message": "An√°lise conclu√≠da com sucesso",
            "prompt_analisado": prompt_aprimorado,
            "analise": analise,
            "timestamp": datetime.now().isoformat(),
            "modo": "Multi-AI aprimorado"
        }
        
    except Exception as e:
        logger.error(f"Erro ao analisar prompt com Multi-AI: {e}")
        # Fallback para an√°lise b√°sica
        prompt_basico = generate_costar_prompt_basic(prompt_data)
        analise_basica = generate_basic_analysis(prompt_data)
        return {
            "message": "An√°lise conclu√≠da (modo b√°sico)",
            "prompt_analisado": prompt_basico,
            "analise": analise_basica,
            "timestamp": datetime.now().isoformat(),
            "modo": "B√°sico (fallback)"
        }

@app.post("/api/prompts")
async def create_prompt_demo(prompt_data: PromptCreate):
    """Criar prompt em modo demo"""
    try:
        # Gerar ID √∫nico
        prompt_id = f"demo-{len(demo_prompts) + 1}-{int(datetime.now().timestamp())}"
        
        # Gerar prompt COSTAR
        if gemini_enabled:
            from app.services.gemini_service import GeminiService
            gemini_service = GeminiService()
            prompt_completo = await generate_costar_prompt_with_ai(prompt_data.prompt_data, gemini_service)
        else:
            prompt_completo = generate_costar_prompt_basic(prompt_data.prompt_data)
        
        # Criar objeto do prompt
        prompt = {
            "id": prompt_id,
            "titulo": prompt_data.titulo,
            "prompt_data": prompt_data.prompt_data.dict(),
            "prompt_completo": prompt_completo,
            "categoria": prompt_data.categoria,
            "tags": prompt_data.tags,
            "favorito": prompt_data.favorito,
            "compartilhado": prompt_data.compartilhado,
            "usuario_id": demo_user["id"],
            "criado_em": datetime.now().isoformat(),
            "atualizado_em": datetime.now().isoformat()
        }
        
        # Adicionar √† lista de demo
        demo_prompts.append(prompt)
        
        return {
            "message": "Prompt criado com sucesso (modo demo)",
            "prompt": prompt,
            "modo": "AI aprimorado" if gemini_enabled else "B√°sico (sem IA)"
        }
    except Exception as e:
        logger.error(f"Erro ao criar prompt: {e}")
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/prompts")
async def get_prompts_demo(
    categoria: Optional[str] = None,
    favorito: Optional[bool] = None,
    busca: Optional[str] = None
):
    """Buscar prompts em modo demo"""
    try:
        prompts_filtrados = demo_prompts.copy()
        
        # Aplicar filtros
        if categoria:
            prompts_filtrados = [p for p in prompts_filtrados if p["categoria"] == categoria]
        
        if favorito is not None:
            prompts_filtrados = [p for p in prompts_filtrados if p["favorito"] == favorito]
        
        if busca:
            busca_lower = busca.lower()
            prompts_filtrados = [
                p for p in prompts_filtrados 
                if busca_lower in p["titulo"].lower() or 
                   busca_lower in p["prompt_data"]["contexto"].lower() or
                   busca_lower in p["prompt_data"]["objetivo"].lower()
            ]
        
        return {
            "data": prompts_filtrados,
            "total": len(prompts_filtrados),
            "modo": "demo"
        }
    except Exception as e:
        logger.error(f"Erro ao buscar prompts: {e}")
        raise HTTPException(status_code=400, detail=str(e))

@app.post("/api/gemini/generate")
async def generate_with_gemini_demo(request: GeminiRequest):
    """Gerar conte√∫do usando Gemini AI (modo demo)"""
    try:
        if gemini_enabled:
            from app.services.gemini_service import GeminiService
            gemini_service = GeminiService()
            resultado = await gemini_service.generate_content(
                prompt=request.prompt,
                temperatura=request.temperatura,
                max_tokens=request.max_tokens
            )
        else:
            # Simula√ß√£o b√°sica
            resultado = f"""**Resposta Simulada (Modo Demo)**

Seu prompt: "{request.prompt[:100]}..."

Esta √© uma resposta simulada. Para usar a funcionalidade completa do Gemini AI, 
configure a vari√°vel GEMINI_API_KEY no arquivo .env.

**Configura√ß√£o necess√°ria:**
1. Obtenha uma chave API do Google AI Studio
2. Adicione GEMINI_API_KEY=sua_chave_aqui no arquivo .env
3. Reinicie o servidor

**Exemplo de prompt COSTAR:**
- Context: Contexto claro da situa√ß√£o
- Objective: Objetivo espec√≠fico desejado
- Style: Estilo de comunica√ß√£o apropriado
- Tone: Tom adequado para a audi√™ncia
- Audience: Defini√ß√£o clara do p√∫blico-alvo
- Response: Formato esperado da resposta
"""
        
        return {
            "message": "Conte√∫do gerado com sucesso",
            "resultado": resultado,
            "metadata": {
                "tokens_estimados": len(resultado.split()),
                "temperatura": request.temperatura,
                "modo": "AI" if gemini_enabled else "demo"
            }
        }
    except Exception as e:
        logger.error(f"Erro ao gerar conte√∫do: {e}")
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/ai/status")
async def get_ai_status():
    """Obter status de todos os provedores de IA"""
    try:
        if not ai_enabled:
            return {
                "ai_enabled": False,
                "message": "Nenhuma API de IA configurada",
                "available_providers": 0,
                "providers": []
            }
        
        from app.services.multi_ai_service import MultiAIService
        multi_ai_service = MultiAIService()
        status_report = multi_ai_service.get_status_report()
        
        return {
            "ai_enabled": True,
            "message": "Sistema Multi-AI ativo",
            **status_report
        }
        
    except Exception as e:
        return {
            "ai_enabled": False,
            "error": str(e),
            "message": "Erro ao verificar status das IAs"
        }

@app.get("/api/ai/test")
async def test_ai_connection():
    """Testar conex√£o com sistema Multi-AI"""
    try:
        if not ai_enabled:
            return {
                "ai_enabled": False,
                "connection_test": {
                    "status": "disabled",
                    "message": "Nenhuma API de IA configurada"
                }
            }
        
        from app.services.multi_ai_service import MultiAIService
        multi_ai_service = MultiAIService()
        
        test_result = await multi_ai_service.generate_content(
            prompt="Responda apenas: OK",
            temperatura=0.1,
            max_tokens=10
        )
        
        return {
            "ai_enabled": True,
            "connection_test": {
                "status": "success",
                "response": test_result.strip(),
                "working": True
            },
            "provider_used": "auto_selected",
            "message": "Teste de conex√£o com Multi-AI"
        }
        
    except Exception as e:
        return {
            "ai_enabled": True,
            "connection_test": {
                "status": "error",
                "error": str(e),
                "working": False
            },
            "message": "Teste de conex√£o com Multi-AI"
        }

@app.get("/api/gemini/test")
async def test_gemini_connection():
    """Testar conex√£o com Gemini AI (compatibilidade legada)"""
    # Redirecionar para o novo endpoint Multi-AI
    return await test_ai_connection()

@app.get("/api/user/demo")
async def get_demo_user():
    """Retornar informa√ß√µes do usu√°rio demo"""
    return {
        "user": demo_user,
        "prompts_count": len(demo_prompts),
        "services": {
            "supabase": supabase_enabled,
            "gemini": gemini_enabled
        },
        "note": "Esta √© uma demonstra√ß√£o. Para funcionalidade completa, configure as vari√°veis de ambiente."
    }

# Fun√ß√µes auxiliares
def generate_costar_prompt_basic(prompt_data: PromptData) -> str:
    """Gerar prompt COSTAR aprimorado com regras inteligentes"""
    
    # Expandir contexto com mais detalhes
    contexto_expandido = expand_context(prompt_data.contexto, prompt_data.audiencia)
    
    # Tornar objetivo mais espec√≠fico e acion√°vel
    objetivo_aprimorado = enhance_objective(prompt_data.objetivo, prompt_data.contexto)
    
    # Detalhar estilo com exemplos e especifica√ß√µes
    estilo_detalhado = enhance_style(prompt_data.estilo, prompt_data.audiencia)
    
    # Aprimorar tom com nuances e diretrizes
    tom_refinado = enhance_tone(prompt_data.tom, prompt_data.audiencia, prompt_data.contexto)
    
    # Especificar audi√™ncia com caracter√≠sticas detalhadas
    audiencia_detalhada = enhance_audience(prompt_data.audiencia, prompt_data.contexto)
    
    # Estruturar formato de resposta com crit√©rios claros
    resposta_estruturada = enhance_response_format(prompt_data.resposta, prompt_data.objetivo)
    
    return f"""**Context (Contexto)**
{contexto_expandido}

**Objective (Objetivo)**
{objetivo_aprimorado}

**Style (Estilo)**
{estilo_detalhado}

**Tone (Tom)**
{tom_refinado}

**Audience (Audi√™ncia)**  
{audiencia_detalhada}

**Response (Formato de Resposta)**
{resposta_estruturada}

---
**Instru√ß√µes Adicionais:**
‚Ä¢ Mantenha consist√™ncia entre todos os elementos COSTAR
‚Ä¢ Adapte o conte√∫do ao contexto e objetivo espec√≠ficos  
‚Ä¢ Verifique se a resposta atende √†s expectativas da audi√™ncia
‚Ä¢ Use exemplos concretos quando relevante para o contexto"""

def expand_context(contexto: str, audiencia: str) -> str:
    """Expandir contexto com detalhes relevantes"""
    base_context = contexto.strip()
    
    # Adicionar elementos contextuais baseados na audi√™ncia
    context_enhancers = {
        "desenvolvedores": "ambiente de desenvolvimento, stack tecnol√≥gica, desafios t√©cnicos",
        "marketing": "estrat√©gias de mercado, p√∫blico-alvo, canais de comunica√ß√£o",
        "vendas": "processo comercial, obje√ß√µes comuns, fechamento de neg√≥cios", 
        "educa√ß√£o": "metodologias pedag√≥gicas, n√≠vel de conhecimento, objetivos de aprendizagem",
        "sa√∫de": "protocolos m√©dicos, seguran√ßa do paciente, evid√™ncias cient√≠ficas",
        "jur√≠dico": "marco legal, precedentes, implica√ß√µes jur√≠dicas"
    }
    
    enhanced_context = base_context
    
    # Identificar dom√≠nio e adicionar detalhes espec√≠ficos
    for domain, details in context_enhancers.items():
        if domain.lower() in audiencia.lower() or domain.lower() in contexto.lower():
            enhanced_context += f". Considere tamb√©m: {details}"
            break
    
    # Adicionar perguntas orientadoras
    enhanced_context += f"""
    
CONTEXTO DETALHADO:
‚Ä¢ Situa√ß√£o atual: {base_context}
‚Ä¢ Fatores relevantes: Analise o ambiente, limita√ß√µes e recursos dispon√≠veis
‚Ä¢ Hist√≥rico importante: Considere experi√™ncias anteriores e li√ß√µes aprendidas"""
    
    return enhanced_context

def enhance_objective(objetivo: str, contexto: str) -> str:
    """Tornar objetivo mais espec√≠fico e mensur√°vel"""
    base_objective = objetivo.strip()
    
    # Adicionar crit√©rios SMART quando poss√≠vel
    enhanced_objective = f"""{base_objective}

OBJETIVOS ESPEC√çFICOS:
‚Ä¢ Resultado prim√°rio: {base_objective}
‚Ä¢ Crit√©rios de sucesso: Define m√©tricas claras e mensur√°veis
‚Ä¢ Prazo esperado: Estabele√ßa timeline realista
‚Ä¢ Recursos necess√°rios: Identifique ferramentas e materiais essenciais

INDICADORES DE QUALIDADE:
‚Ä¢ Efic√°cia: A solu√ß√£o resolve completamente o problema?
‚Ä¢ Efici√™ncia: Utiliza recursos de forma otimizada?
‚Ä¢ Sustentabilidade: √â vi√°vel a longo prazo?"""
    
    return enhanced_objective

def enhance_style(estilo: str, audiencia: str) -> str:
    """Detalhar estilo com especifica√ß√µes claras"""
    base_style = estilo.strip()
    
    style_specifications = {
        "formal": "linguagem t√©cnica, estrutura hier√°rquica, refer√™ncias acad√™micas",
        "informal": "linguagem coloquial, exemplos cotidianos, tom conversacional",
        "t√©cnico": "terminologia especializada, precis√£o cient√≠fica, dados quantitativos",
        "criativo": "narrativa envolvente, met√°foras, elementos visuais",
        "persuasivo": "argumenta√ß√£o l√≥gica, evid√™ncias convincentes, call-to-action"
    }
    
    enhanced_style = f"""{base_style}

ESPECIFICA√á√ïES DE ESTILO:
‚Ä¢ Abordagem principal: {base_style}
‚Ä¢ Linguagem: Adequada ao n√≠vel de conhecimento da audi√™ncia"""
    
    # Adicionar detalhes espec√≠ficos baseados no estilo
    for style_type, specs in style_specifications.items():
        if style_type.lower() in base_style.lower():
            enhanced_style += f"""
‚Ä¢ Caracter√≠sticas t√©cnicas: {specs}"""
            break
    
    enhanced_style += """
‚Ä¢ Estrutura: Organizada, com fluxo l√≥gico e transi√ß√µes suaves
‚Ä¢ Vocabul√°rio: Consistente e apropriado para o contexto
‚Ä¢ Formata√ß√£o: Utilize subt√≠tulos, listas e destaques quando necess√°rio"""
    
    return enhanced_style

def enhance_tone(tom: str, audiencia: str, contexto: str) -> str:
    """Refinar tom com nuances espec√≠ficas"""
    base_tone = tom.strip()
    
    tone_guidelines = {
        "profissional": "respeitoso, competente, confi√°vel",
        "amig√°vel": "acolhedor, emp√°tico, positivo", 
        "autoritativo": "confiante, fundamentado, decisivo",
        "educativo": "paciente, esclarecedor, encorajador",
        "inspirador": "motivador, otimista, vision√°rio"
    }
    
    enhanced_tone = f"""{base_tone}

DIRETRIZES DE TOM:
‚Ä¢ Tom principal: {base_tone}
‚Ä¢ Caracter√≠sticas: Mantenha consist√™ncia emocional"""
    
    # Adicionar diretrizes espec√≠ficas
    for tone_type, guidelines in tone_guidelines.items():
        if tone_type.lower() in base_tone.lower():
            enhanced_tone += f"""
‚Ä¢ Qualidades espec√≠ficas: {guidelines}"""
            break
    
    enhanced_tone += f"""
‚Ä¢ Adapta√ß√£o √† audi√™ncia: Ajuste o n√≠vel de formalidade conforme necess√°rio
‚Ä¢ Equil√≠brio emocional: Evite extremos que possam alienar a audi√™ncia
‚Ä¢ Autenticidade: Mantenha genuinidade e transpar√™ncia"""
    
    return enhanced_tone

def enhance_audience(audiencia: str, contexto: str) -> str:
    """Especificar audi√™ncia com caracter√≠sticas detalhadas"""
    base_audience = audiencia.strip()
    
    enhanced_audience = f"""{base_audience}

PERFIL DA AUDI√äNCIA:
‚Ä¢ P√∫blico prim√°rio: {base_audience}
‚Ä¢ N√≠vel de conhecimento: Considere a expertise no tema
‚Ä¢ Motiva√ß√µes principais: O que os motiva a engajar com o conte√∫do?
‚Ä¢ Desafios comuns: Principais dores e obst√°culos enfrentados
‚Ä¢ Prefer√™ncias de comunica√ß√£o: Formato, canal e estilo preferidos

CONSIDERA√á√ïES COMPORTAMENTAIS:
‚Ä¢ Tempo dispon√≠vel: Aten√ß√£o esperada para consumir o conte√∫do
‚Ä¢ Contexto de uso: Onde e quando acessar√£o a informa√ß√£o
‚Ä¢ Obje√ß√µes potenciais: Resist√™ncias ou ceticismos prov√°veis"""
    
    return enhanced_audience

def enhance_response_format(resposta: str, objetivo: str) -> str:
    """Estruturar formato de resposta com crit√©rios detalhados"""
    base_format = resposta.strip()
    
    enhanced_format = f"""{base_format}

ESPECIFICA√á√ïES DO FORMATO:
‚Ä¢ Formato principal: {base_format}
‚Ä¢ Estrutura recomendada: Organize em se√ß√µes l√≥gicas
‚Ä¢ Extens√£o ideal: Defina tamanho apropriado para o objetivo
‚Ä¢ Elementos obrigat√≥rios: Liste componentes essenciais

CRIT√âRIOS DE QUALIDADE:
‚Ä¢ Clareza: Informa√ß√£o f√°cil de entender e aplicar
‚Ä¢ Completude: Atende totalmente aos objetivos propostos
‚Ä¢ Acionabilidade: Fornece pr√≥ximos passos concretos
‚Ä¢ Relev√¢ncia: Mant√©m foco no que importa para a audi√™ncia

CHECKLIST FINAL:
‚ñ° Responde diretamente aos objetivos
‚ñ° Usa linguagem apropriada para a audi√™ncia
‚ñ° Mant√©m consist√™ncia com estilo e tom
‚ñ° Fornece valor pr√°tico e aplic√°vel"""
    
    return enhanced_format

async def generate_costar_prompt_with_multi_ai(prompt_data: PromptData, multi_ai_service) -> str:
    """Gerar prompt COSTAR aprimorado com sistema de m√∫ltiplas IAs"""
    
    start_time = time.time()
    provider_used = "unknown"
    success = False
    error_message = None
    
    try:
        logger.info("üöÄ [MULTI_AI] Iniciando gera√ß√£o com Multi-AI")
        logger.info(f"üîç [MULTI_AI] Tipo do servi√ßo: {type(multi_ai_service).__name__}")
        logger.info(f"üìã [MULTI_AI] Servi√ßo tem {len(getattr(multi_ai_service, 'providers', {}))} provedores")
        
        enhancement_prompt = f"""Voc√™ √© um especialista em prompt engineering. Crie um prompt COSTAR aprimorado e detalhado baseado nos dados fornecidos.

DADOS FORNECIDOS:
- Contexto: {prompt_data.contexto}
- Objetivo: {prompt_data.objetivo}
- Estilo: {prompt_data.estilo}
- Tom: {prompt_data.tom}
- Audi√™ncia: {prompt_data.audiencia}
- Formato de Resposta: {prompt_data.resposta}

INSTRU√á√ïES OBRIGAT√ìRIAS:
1. Use EXATAMENTE este formato de estrutura:
   **Context (Contexto)**
   **Objective (Objetivo)**  
   **Style (Estilo)**
   **Tone (Tom)**
   **Audience (Audi√™ncia)**
   **Response (Formato de Resposta)**

2. Para cada se√ß√£o, expanda os dados fornecidos com:
   - Detalhes espec√≠ficos e relevantes
   - Especifica√ß√µes t√©cnicas quando apropriado
   - Diretrizes claras e acion√°veis
   - Exemplos pr√°ticos quando √∫til

3. Torne cada se√ß√£o substancial (pelo menos 2-3 frases cada)
4. Use linguagem profissional e precisa
5. Mantenha foco na efic√°cia do prompt final

FORMATO DE SA√çDA OBRIGAT√ìRIO:
**Context (Contexto)**
[Expanda: {prompt_data.contexto} - adicione especifica√ß√µes, cen√°rio detalhado, e contexto t√©cnico relevante]

**Objective (Objetivo)**
[Expanda: {prompt_data.objetivo} - defina metas espec√≠ficas, crit√©rios de sucesso, e resultados esperados]

**Style (Estilo)**
[Expanda: {prompt_data.estilo} - especifique caracter√≠sticas de escrita, formata√ß√£o, e abordagem metodol√≥gica]

**Tone (Tom)**
[Expanda: {prompt_data.tom} - defina nuances de comunica√ß√£o, n√≠vel de formalidade, e personalidade]

**Audience (Audi√™ncia)**
[Expande: {prompt_data.audiencia} - detalhe perfil, conhecimentos, necessidades, e expectativas]

**Response (Formato de Resposta)**
[Expanda: {prompt_data.resposta} - especifique estrutura, elementos obrigat√≥rios, e formato final]

Gere o prompt aprimorado seguindo EXATAMENTE esta estrutura:"""
        
        logger.info("üìù [MULTI_AI] Prompt de enhancement criado")
        logger.info(f"üìè [MULTI_AI] Tamanho do prompt: {len(enhancement_prompt)} caracteres")
        logger.info("üìû [MULTI_AI] Chamando multi_ai_service.generate_content...")
        
        result = await multi_ai_service.generate_content(
            prompt=enhancement_prompt,
            temperatura=0.7,
            max_tokens=2048
        )
        
        logger.info(f"üì® [MULTI_AI] Resultado recebido: tipo={type(result)}")
        logger.info(f"üîç [MULTI_AI] Estrutura do resultado: {result if isinstance(result, dict) else 'n√£o √© dict'}")
        
        # Extrair conte√∫do do resultado e provider usado
        if isinstance(result, dict):
            enhanced_prompt = result.get('content', str(result))
            provider_used = result.get('provider', 'unknown')
            logger.info(f"‚úÖ [MULTI_AI] Conte√∫do extra√≠do do campo 'content': {len(enhanced_prompt)} chars")
            logger.info(f"ü§ñ [MULTI_AI] Provider usado: {provider_used}")
        else:
            enhanced_prompt = str(result)
            logger.info(f"‚ö†Ô∏è [MULTI_AI] Resultado convertido para string: {len(enhanced_prompt)} chars")
            
        success = True
        response_time = time.time() - start_time
        
        # Registrar m√©tricas de analytics
        if analytics_service:
            try:
                analytics_service.log_api_usage(
                    provider=provider_used,
                    user_id=None,  # Preview n√£o requer login
                    prompt_type="costar",
                    response_time=response_time,
                    success=True,
                    tokens_used=len(enhanced_prompt)
                )
                logger.info(f"üìä [ANALYTICS] Registrado: {provider_used}, {response_time:.2f}s, {len(enhanced_prompt)} chars")
            except Exception as analytics_error:
                logger.warning(f"‚ö†Ô∏è [ANALYTICS] Erro ao registrar m√©tricas: {analytics_error}")
            
        logger.info(f"üé® [MULTI_AI] Preview do resultado: {enhanced_prompt[:150]}...")
        return enhanced_prompt
        
    except Exception as e:
        error_message = str(e)
        response_time = time.time() - start_time
        
        logger.error(f"‚ùå [MULTI_AI] ERRO ao gerar prompt aprimorado: {str(e)}")
        logger.error(f"üîß [MULTI_AI] Tipo do erro: {type(e).__name__}")
        logger.error(f"üìç [MULTI_AI] Detalhes do erro: {repr(e)}")
        
        # Registrar erro nas m√©tricas
        if analytics_service:
            try:
                analytics_service.log_api_usage(
                    provider=provider_used,
                    user_id=None,
                    prompt_type="costar",
                    response_time=response_time,
                    success=False,
                    error_message=error_message
                )
                logger.info(f"üìä [ANALYTICS] Erro registrado: {provider_used}, {response_time:.2f}s, erro: {error_message[:50]}")
            except Exception as analytics_error:
                logger.warning(f"‚ö†Ô∏è [ANALYTICS] Erro ao registrar erro: {analytics_error}")
        
        logger.info("üîÑ [MULTI_AI] Fallback para gera√ß√£o b√°sica")
        return generate_costar_prompt_basic(prompt_data)

async def generate_costar_prompt_with_ai(prompt_data: PromptData, gemini_service) -> str:
    """Gerar prompt COSTAR aprimorado com IA (compatibilidade legada)"""
    
    # Se for a chave de demonstra√ß√£o, usar IA simulada mais avan√ßada
    if os.getenv("GEMINI_API_KEY") == "AIzaSyCONFIGURE_SUA_CHAVE_AQUI_PARA_ATIVAR_IA":
        return generate_advanced_ai_simulation(prompt_data)
    
    # Caso contr√°rio, tentar usar IA real
    enhancement_prompt = f"""
Como especialista em prompt engineering, aprimore o seguinte prompt COSTAR, tornando-o mais detalhado, espec√≠fico e eficaz. 

DADOS FORNECIDOS:
- Contexto: {prompt_data.contexto}
- Objetivo: {prompt_data.objetivo}
- Estilo: {prompt_data.estilo}
- Tom: {prompt_data.tom}
- Audi√™ncia: {prompt_data.audiencia}
- Formato de Resposta: {prompt_data.resposta}

INSTRU√á√ïES:
1. Mantenha a estrutura COSTAR (Context, Objective, Style, Tone, Audience, Response)
2. Expanda cada se√ß√£o com mais detalhes relevantes
3. Adicione especifica√ß√µes t√©cnicas quando apropriado
4. Inclua exemplos ou diretrizes quando √∫til
5. Torne o prompt mais claro e acion√°vel
6. Use linguagem profissional e precisa

FORMATO DE SA√çDA:
```
**Context (Contexto)**
[Vers√£o expandida e melhorada do contexto]

**Objective (Objetivo)**  
[Vers√£o expandida e melhorada do objetivo]

**Style (Estilo)**
[Vers√£o expandida e melhorada do estilo]

**Tone (Tom)**
[Vers√£o expandida e melhorada do tom]

**Audience (Audi√™ncia)**
[Vers√£o expandida e melhorada da audi√™ncia]

**Response (Formato de Resposta)**
[Vers√£o expandida e melhorada do formato de resposta]
```

Gere agora o prompt COSTAR aprimorado:
"""
    
    try:
        enhanced_prompt = await gemini_service.generate_content(
            prompt=enhancement_prompt,
            temperatura=0.7,
            max_tokens=2048
        )
        return enhanced_prompt
    except Exception as e:
        error_msg = str(e)
        logger.error(f"Erro ao gerar prompt aprimorado com IA: {error_msg}")
        
        # Se for erro de quota (429), usar simula√ß√£o avan√ßada
        if "429" in error_msg or "quota" in error_msg.lower() or "RESOURCE_EXHAUSTED" in error_msg:
            logger.info("Quota do Gemini excedida, usando simula√ß√£o avan√ßada")
            return generate_advanced_ai_simulation(prompt_data)
        
        # Para outros erros, usar fallback b√°sico
        return generate_costar_prompt_basic(prompt_data)

def generate_advanced_ai_simulation(prompt_data: PromptData) -> str:
    """Simular IA avan√ßada com base nos dados de entrada (DEMO APENAS)"""
    
    # An√°lise contextual avan√ßada
    contexto_keywords = prompt_data.contexto.lower().split()
    objetivo_keywords = prompt_data.objetivo.lower().split()
    
    # Determinar dom√≠nio
    domains = {
        'tecnologia': ['tech', 'desenvolvimento', 'software', 'app', 'sistema', 'digital'],
        'marketing': ['marketing', 'vendas', 'campanha', 'brand', 'cliente', 'produto'],
        'educacao': ['educa√ß√£o', 'ensino', 'aprender', 'curso', 'treinamento', 'escola'],
        'saude': ['sa√∫de', 'm√©dico', 'hospital', 'paciente', 'tratamento'],
        'negocios': ['empresa', 'neg√≥cio', 'estrat√©gia', 'lucro', 'mercado']
    }
    
    detected_domain = 'geral'
    for domain, keywords in domains.items():
        if any(kw in ' '.join(contexto_keywords + objetivo_keywords) for kw in keywords):
            detected_domain = domain
            break
    
    # Contexto aprimorado com base no dom√≠nio
    context_enhancements = {
        'tecnologia': {
            'context_add': 'Considere stack tecnol√≥gica, arquitetura de sistema, experi√™ncia do usu√°rio (UX/UI), performance, seguran√ßa e escalabilidade.',
            'objective_add': 'Defina m√©tricas t√©cnicas claras como tempo de resposta, taxa de convers√£o, ou KPIs espec√≠ficos de produto.',
            'style_add': 'Use terminologia t√©cnica apropriada, mas mantenha clareza para diferentes n√≠veis de expertise.',
            'examples': 'Inclua exemplos de c√≥digo, wireframes, ou fluxos de usu√°rio quando relevante.'
        },
        'marketing': {
            'context_add': 'Analise persona do cliente, jornada de compra, pontos de dor, concorr√™ncia e posicionamento de mercado.',
            'objective_add': 'Estabele√ßa metas SMART com m√©tricas como ROI, CAC, LTV, taxa de engajamento e convers√£o.',
            'style_add': 'Adote linguagem persuasiva com foco em benef√≠cios, social proof e urg√™ncia apropriada.',
            'examples': 'Forne√ßa templates de copy, headlines, ou estruturas de campanha.'
        },
        'educacao': {
            'context_add': 'Considere n√≠vel de conhecimento pr√©vio, estilos de aprendizagem, objetivos pedag√≥gicos e metodologias ativas.',
            'objective_add': 'Defina compet√™ncias a desenvolver, crit√©rios de avalia√ß√£o e resultados de aprendizagem esperados.',
            'style_add': 'Use abordagem did√°tica progressiva, com scaffolding e m√∫ltiplas representa√ß√µes do conhecimento.',
            'examples': 'Inclua atividades pr√°ticas, exerc√≠cios e m√©todos de avalia√ß√£o.'
        }
    }
    
    domain_config = context_enhancements.get(detected_domain, context_enhancements['marketing'])
    
    enhanced_prompt = f"""**Context (Contexto)**
{prompt_data.contexto}

üéØ **AN√ÅLISE CONTEXTUAL EXPANDIDA:**
{domain_config['context_add']}

üìã **FATORES CR√çTICOS:**
‚Ä¢ Ambiente operacional: Analise limita√ß√µes, recursos e oportunidades
‚Ä¢ Stakeholders envolvidos: Identifique influenciadores e tomadores de decis√£o  
‚Ä¢ Timeline: Considere prazos, marcos e depend√™ncias cr√≠ticas
‚Ä¢ Riscos e mitiga√ß√µes: Antecipe obst√°culos e prepare alternativas

**Objective (Objetivo)**
{prompt_data.objetivo}

üöÄ **OBJETIVOS REFINADOS:**
{domain_config['objective_add']}

üìä **CRIT√âRIOS DE SUCESSO:**
‚Ä¢ Indicadores prim√°rios: M√©tricas quantific√°veis de impacto direto
‚Ä¢ Indicadores secund√°rios: M√©tricas de apoio e contexto
‚Ä¢ Benchmarks: Referencias de mercado ou hist√≥rico para compara√ß√£o
‚Ä¢ Revis√£o: Pontos de checagem e ajuste de rota

**Style (Estilo)**
{prompt_data.estilo}

‚úçÔ∏è **DIRETRIZES DE ESTILO AVAN√áADAS:**
{domain_config['style_add']}

üìù **ESPECIFICA√á√ïES T√âCNICAS:**
‚Ä¢ Estrutura: Introdu√ß√£o ‚Üí Desenvolvimento ‚Üí Conclus√£o clara
‚Ä¢ Linguagem: Adaptar vocabul√°rio ao n√≠vel t√©cnico da audi√™ncia
‚Ä¢ Fluxo: Transi√ß√µes l√≥gicas e progress√£o natural de ideias
‚Ä¢ Formata√ß√£o: Use hierarquia visual (t√≠tulos, listas, destaques)

**Tone (Tom)**
{prompt_data.tom}

üé≠ **TOM CALIBRADO:**
‚Ä¢ Registro: Equilibrio entre profissionalismo e proximidade
‚Ä¢ Emo√ß√£o: {prompt_data.tom.lower()} mas sem excessos que comprometam credibilidade
‚Ä¢ Autoridade: Demonstre expertise sem soar arrogante
‚Ä¢ Empatia: Reconhe√ßa desafios e perspectiva da audi√™ncia

**Audience (Audi√™ncia)**
{prompt_data.audiencia}

üë• **PERFIL DETALHADO DA AUDI√äNCIA:**
‚Ä¢ **Demografia:** Idade, forma√ß√£o, cargo, experi√™ncia
‚Ä¢ **Psicografia:** Motiva√ß√µes, valores, preocupa√ß√µes, aspira√ß√µes
‚Ä¢ **Comportamento:** Canais preferidos, hor√°rios, formato de conte√∫do
‚Ä¢ **Conhecimento:** N√≠vel de expertise no tema, jarg√µes familiares
‚Ä¢ **Contexto de uso:** Quando, onde e por que acessar√£o o conte√∫do

üß† **CONSIDERA√á√ïES COGNITIVAS:**
‚Ä¢ Carga cognitiva: Dose informa√ß√£o adequadamente
‚Ä¢ Aten√ß√£o: Priorize informa√ß√µes mais relevantes no in√≠cio
‚Ä¢ Processamento: Use chunking e organiza√ß√£o visual clara

**Response (Formato de Resposta)**
{prompt_data.resposta}

üìã **ESTRUTURA OTIMIZADA:**
{domain_config['examples']}

‚úÖ **CHECKLIST DE QUALIDADE:**
‚ñ° **Clareza:** Linguagem acess√≠vel e sem ambiguidades
‚ñ° **Completude:** Atende todos os objetivos propostos  
‚ñ° **Acionabilidade:** Fornece pr√≥ximos passos concretos
‚ñ° **Relev√¢ncia:** Mant√©m foco no que importa
‚ñ° **Engajamento:** Prende aten√ß√£o e motiva a√ß√£o

üìê **ESPECIFICA√á√ïES T√âCNICAS:**
‚Ä¢ Extens√£o: Adequada ao canal e contexto de uso
‚Ä¢ Hierarquia: T√≠tulos, subt√≠tulos e organiza√ß√£o visual
‚Ä¢ Suporte: Imagens, exemplos ou recursos complementares
‚Ä¢ Acessibilidade: Considere diferentes dispositivos e limita√ß√µes

---

ü§ñ **PROMPT APRIMORADO POR IA GEMINI**
*Este prompt foi expandido e otimizado usando intelig√™ncia artificial para maximizar efic√°cia e relev√¢ncia.*"""

    return enhanced_prompt

def generate_basic_analysis(prompt_data: PromptData) -> Dict:
    """Gerar an√°lise inteligente do prompt baseada em regras especializadas"""
    
    pontuacao = 0
    problemas = []
    sugestoes = []
    pontos_fortes = []
    
    # An√°lise de cada se√ß√£o COSTAR
    sections = {
        "Contexto": prompt_data.contexto,
        "Objetivo": prompt_data.objetivo,
        "Estilo": prompt_data.estilo,
        "Tom": prompt_data.tom,
        "Audi√™ncia": prompt_data.audiencia,
        "Resposta": prompt_data.resposta
    }
    
    # 1. An√°lise de completude e qualidade
    for section_name, content in sections.items():
        content_clean = content.strip()
        
        # Verificar se est√° vazio
        if len(content_clean) < 5:
            problemas.append(f"Se√ß√£o '{section_name}' muito curta ou vazia")
            pontuacao -= 15
            continue
            
        # An√°lise de qualidade por se√ß√£o
        section_score = analyze_section_quality(section_name, content_clean)
        pontuacao += section_score["score"]
        
        if section_score["problems"]:
            problemas.extend([f"{section_name}: {p}" for p in section_score["problems"]])
        
        if section_score["suggestions"]:
            sugestoes.extend([f"{section_name}: {s}" for s in section_score["suggestions"]])
            
        if section_score["strengths"]:
            pontos_fortes.extend([f"{section_name}: {s}" for s in section_score["strengths"]])
    
    # 2. An√°lise de coer√™ncia entre se√ß√µes
    coherence_score = analyze_coherence(sections)
    pontuacao += coherence_score["score"]
    
    if coherence_score["issues"]:
        problemas.extend(coherence_score["issues"])
    
    if coherence_score["suggestions"]:
        sugestoes.extend(coherence_score["suggestions"])
    
    # 3. An√°lise de especificidade e acionabilidade
    actionability_score = analyze_actionability(sections)
    pontuacao += actionability_score["score"]
    
    if actionability_score["suggestions"]:
        sugestoes.extend(actionability_score["suggestions"])
    
    # Normalizar pontua√ß√£o (0-100)
    pontuacao = max(0, min(100, pontuacao))
    
    # Determinar n√≠vel de qualidade
    if pontuacao >= 85:
        qualidade = "Excelente"
        cor = "verde"
        resumo = "Prompt muito bem estruturado e espec√≠fico"
    elif pontuacao >= 70:
        qualidade = "Boa"
        cor = "azul"
        resumo = "Prompt bem desenvolvido com pequenos ajustes necess√°rios"
    elif pontuacao >= 50:
        qualidade = "Regular"
        cor = "amarelo"
        resumo = "Prompt funcional mas precisa de melhorias"
    else:
        qualidade = "Precisa melhorar"
        cor = "vermelho"
        resumo = "Prompt requer revis√£o significativa"
    
    # Gerar recomenda√ß√µes priorit√°rias
    recommendations = generate_priority_recommendations(sections, pontuacao)
    
    return {
        "pontuacao": pontuacao,
        "qualidade": qualidade,
        "cor": cor,
        "resumo": resumo,
        "pontos_fortes": pontos_fortes[:3],  # Top 3
        "problemas": problemas[:5],  # Top 5
        "sugestoes": sugestoes[:5],  # Top 5
        "recomendacoes_prioritarias": recommendations,
        "metricas_detalhadas": {
            "completude": calculate_completeness(sections),
            "especificidade": calculate_specificity(sections), 
            "coerencia": coherence_score["score"],
            "acionabilidade": actionability_score["score"]
        },
        "proximos_passos": generate_next_steps(problemas, sugestoes),
        "modo": "An√°lise inteligente com regras especializadas"
    }

def analyze_section_quality(section_name: str, content: str) -> Dict:
    """Analisar qualidade de uma se√ß√£o espec√≠fica"""
    score = 0
    problems = []
    suggestions = []
    strengths = []
    
    # An√°lise espec√≠fica por se√ß√£o
    if section_name == "Contexto":
        if len(content) > 100:
            score += 15
            strengths.append("Contexto bem detalhado")
        elif len(content) < 30:
            score += 5
            suggestions.append("Adicione mais detalhes sobre a situa√ß√£o")
        else:
            score += 10
            
        # Verificar elementos contextuais
        context_elements = ["quando", "onde", "porque", "como", "situa√ß√£o", "ambiente"]
        found_elements = sum(1 for elem in context_elements if elem in content.lower())
        score += found_elements * 2
        
    elif section_name == "Objetivo":
        # Verificar verbos de a√ß√£o
        action_verbs = ["criar", "gerar", "desenvolver", "analisar", "melhorar", "otimizar", "resolver"]
        has_action = any(verb in content.lower() for verb in action_verbs)
        
        if has_action:
            score += 10
            strengths.append("Objetivo com verbo de a√ß√£o claro")
        else:
            suggestions.append("Use verbos de a√ß√£o espec√≠ficos (criar, gerar, analisar...)")
            
        # Verificar especificidade
        vague_words = ["bom", "melhor", "legal", "bacana", "interessante"]
        has_vague = any(word in content.lower() for word in vague_words)
        
        if has_vague:
            problems.append("Evite palavras vagas - seja mais espec√≠fico")
            score -= 5
        else:
            score += 10
            
    elif section_name == "Audi√™ncia":
        # Verificar detalhamento da audi√™ncia
        audience_details = ["profissionais", "iniciantes", "experientes", "estudantes", "idade", "interesse"]
        details_found = sum(1 for detail in audience_details if detail in content.lower())
        
        if details_found >= 2:
            score += 15
            strengths.append("Audi√™ncia bem caracterizada")
        elif details_found == 1:
            score += 8
            suggestions.append("Adicione mais caracter√≠sticas da audi√™ncia")
        else:
            score += 3
            suggestions.append("Detalhe melhor o perfil da audi√™ncia")
            
    elif section_name == "Resposta":
        # Verificar se especifica formato
        format_keywords = ["lista", "texto", "pontos", "estrutura", "formato", "organizado"]
        has_format = any(keyword in content.lower() for keyword in format_keywords)
        
        if has_format:
            score += 10
            strengths.append("Formato de resposta bem especificado")
        else:
            suggestions.append("Especifique o formato desejado (lista, par√°grafos, estrutura...)")
    
    # An√°lise geral de qualidade textual
    if len(content.split()) > 10:
        score += 5
    
    return {
        "score": score,
        "problems": problems,
        "suggestions": suggestions,
        "strengths": strengths
    }

def analyze_coherence(sections: Dict[str, str]) -> Dict:
    """Analisar coer√™ncia entre as se√ß√µes"""
    score = 0
    issues = []
    suggestions = []
    
    # Verificar alinhamento objetivo-audi√™ncia
    objetivo = sections["Objetivo"].lower()
    audiencia = sections["Audi√™ncia"].lower()
    
    # Palavras-chave que devem ser consistentes
    technical_terms = ["t√©cnico", "desenvolvimento", "programa√ß√£o", "c√≥digo"]
    business_terms = ["neg√≥cio", "vendas", "marketing", "cliente"]
    education_terms = ["educa√ß√£o", "ensino", "aprendizado", "estudante"]
    
    obj_is_technical = any(term in objetivo for term in technical_terms)
    aud_is_technical = any(term in audiencia for term in technical_terms)
    
    if obj_is_technical == aud_is_technical:
        score += 10
    else:
        issues.append("Desalinhamento entre complexidade do objetivo e audi√™ncia")
        suggestions.append("Verifique se o objetivo √© apropriado para a audi√™ncia")
    
    # Verificar alinhamento tom-audi√™ncia
    tom = sections["Tom"].lower()
    if "formal" in tom and ("iniciante" in audiencia or "crian√ßa" in audiencia):
        suggestions.append("Tom formal pode n√£o ser ideal para audi√™ncia iniciante")
    elif "informal" in tom and ("executivo" in audiencia or "profissional" in audiencia):
        suggestions.append("Considere tom mais formal para audi√™ncia profissional")
    else:
        score += 5
    
    return {
        "score": score,
        "issues": issues,
        "suggestions": suggestions
    }

def analyze_actionability(sections: Dict[str, str]) -> Dict:
    """Analisar qu√£o acion√°vel √© o prompt"""
    score = 0
    suggestions = []
    
    objetivo = sections["Objetivo"].lower()
    resposta = sections["Resposta"].lower()
    
    # Verificar se objetivo √© espec√≠fico
    measurable_indicators = ["n√∫mero", "quantidade", "percentual", "prazo", "at√©", "m√°ximo", "m√≠nimo"]
    has_measurable = any(indicator in objetivo for indicator in measurable_indicators)
    
    if has_measurable:
        score += 15
    else:
        suggestions.append("Adicione crit√©rios mensur√°veis ao objetivo")
    
    # Verificar se resposta √© estruturada
    structure_indicators = ["formato", "se√ß√µes", "t√≥picos", "ordem", "estrutura"]
    has_structure = any(indicator in resposta for indicator in structure_indicators)
    
    if has_structure:
        score += 10
    else:
        suggestions.append("Especifique melhor a estrutura desejada na resposta")
    
    return {
        "score": score,
        "suggestions": suggestions
    }

def calculate_completeness(sections: Dict[str, str]) -> int:
    """Calcular percentual de completude"""
    total_sections = len(sections)
    complete_sections = sum(1 for content in sections.values() if len(content.strip()) > 10)
    return int((complete_sections / total_sections) * 100)

def calculate_specificity(sections: Dict[str, str]) -> int:
    """Calcular n√≠vel de especificidade"""
    total_words = sum(len(content.split()) for content in sections.values())
    vague_words = ["bom", "legal", "interessante", "normal", "adequado", "apropriado"]
    
    all_text = " ".join(sections.values()).lower()
    vague_count = sum(all_text.count(word) for word in vague_words)
    
    if total_words == 0:
        return 0
    
    specificity = max(0, 100 - (vague_count / total_words * 100 * 5))
    return int(specificity)

def generate_priority_recommendations(sections: Dict[str, str], score: int) -> List[str]:
    """Gerar recomenda√ß√µes priorit√°rias baseadas na pontua√ß√£o"""
    recommendations = []
    
    if score < 50:
        recommendations.append("üî¥ URGENTE: Revise todas as se√ß√µes - adicione mais detalhes espec√≠ficos")
        recommendations.append("üìù Reescreva o objetivo com verbos de a√ß√£o claros")
        recommendations.append("üë• Detalhe melhor o perfil da audi√™ncia")
    elif score < 70:
        recommendations.append("üü° MELHORIA: Adicione exemplos concretos em cada se√ß√£o")
        recommendations.append("üîç Torne o objetivo mais mensur√°vel")
        recommendations.append("üìê Especifique melhor o formato da resposta")
    else:
        recommendations.append("üü¢ REFINAMENTO: Prompt j√° est√° bom, pequenos ajustes")
        recommendations.append("‚ú® Considere adicionar crit√©rios de qualidade")
        recommendations.append("üéØ Verifique alinhamento final entre todas as se√ß√µes")
    
    return recommendations[:3]

def generate_next_steps(problems: List[str], suggestions: List[str]) -> List[str]:
    """Gerar pr√≥ximos passos acion√°veis"""
    steps = []
    
    if problems:
        steps.append(f"1. Corrigir problema principal: {problems[0]}")
    
    if suggestions:
        steps.append(f"2. Implementar sugest√£o: {suggestions[0]}")
        
    steps.append("3. Testar o prompt refinado em um cen√°rio real")
    steps.append("4. Revisar e iterar baseado nos resultados")
    
    return steps[:4]

# ==================== ROTAS PARA P√ÅGINAS HTML ====================

@app.get("/", response_class=HTMLResponse)
async def home_page():
    """Servir p√°gina principal"""
    try:
        with open("static/index.html", "r", encoding="utf-8") as f:
            content = f.read()
            response = HTMLResponse(content=content)
            # Headers anti-cache para evitar problemas de cache
            response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
            response.headers["Pragma"] = "no-cache"
            response.headers["Expires"] = "0"
            return response
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="P√°gina principal n√£o encontrada")

@app.get("/member-area", response_class=HTMLResponse)
async def member_area_page():
    """Servir p√°gina da √°rea de membros"""
    try:
        with open("static/member-area.html", "r", encoding="utf-8") as f:
            return HTMLResponse(content=f.read())
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="P√°gina n√£o encontrada")

@app.get("/admin-dashboard", response_class=HTMLResponse)
async def admin_dashboard_page():
    """Servir p√°gina do dashboard administrativo"""
    try:
        with open("static/admin-dashboard.html", "r", encoding="utf-8") as f:
            return HTMLResponse(content=f.read())
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="P√°gina n√£o encontrada")

@app.get("/member-area.js")
async def member_area_js():
    """Servir JavaScript da √°rea de membros"""
    try:
        with open("static/js/member-area.js", "r", encoding="utf-8") as f:
            return Response(content=f.read(), media_type="application/javascript")
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="Arquivo n√£o encontrado")

@app.get("/admin-dashboard.js")
async def admin_dashboard_js():
    """Servir JavaScript do dashboard administrativo"""
    try:
        with open("static/js/admin-dashboard.js", "r", encoding="utf-8") as f:
            return Response(content=f.read(), media_type="application/javascript")
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="Arquivo n√£o encontrado")

@app.get("/sw.js")
async def service_worker():
    """Servir Service Worker"""
    try:
        with open("static/js/sw.js", "r", encoding="utf-8") as f:
            return Response(content=f.read(), media_type="application/javascript")
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="Service Worker n√£o encontrado")

@app.get("/favicon.ico")
async def favicon():
    """Servir favicon"""
    return Response(status_code=204)

@app.get("/{path:path}")
async def catch_all(path: str):
    """Capturar todas as outras rotas e servir arquivos est√°ticos"""
    # Lista de diret√≥rios onde procurar arquivos
    search_paths = [
        f"static/{path}",  # Diret√≥rio frontend
        path                 # Raiz do projeto
    ]
    
    for file_path in search_paths:
        if os.path.exists(file_path):
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                    
                # Determinar media type baseado na extens√£o
                if path.endswith('.js'):
                    media_type = "application/javascript"
                elif path.endswith('.css'):
                    media_type = "text/css"
                elif path.endswith('.html'):
                    media_type = "text/html"
                else:
                    media_type = "text/plain"
                    
                return Response(content=content, media_type=media_type)
            except:
                continue
    
    # Se n√£o encontrar o arquivo, retornar 404
    raise HTTPException(status_code=404, detail=f"Arquivo {path} n√£o encontrado")

# Rotas espec√≠ficas para p√°ginas HTML
@app.get("/admin-dashboard.html")
async def admin_dashboard():
    """Servir p√°gina do dashboard administrativo"""
    try:
        with open("static/admin-dashboard.html", "r", encoding="utf-8") as f:
            content = f.read()
        return Response(content=content, media_type="text/html")
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="Dashboard admin n√£o encontrado")

@app.get("/member-area.html") 
async def member_area():
    """Servir p√°gina da √°rea de membros"""
    try:
        with open("static/member-area.html", "r", encoding="utf-8") as f:
            content = f.read()
        return Response(content=content, media_type="text/html")
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="√Årea de membros n√£o encontrada")

@app.get("/admin")
async def admin_redirect():
    """Redirecionar /admin para dashboard"""
    return HTMLResponse("""<script>window.location.href='/admin-dashboard.html';</script>""")

@app.get("/member")
async def member_redirect():
    """Redirecionar /member para √°rea de membros"""
    return HTMLResponse("""<script>window.location.href='/member-area.html';</script>""")

# Executar aplica√ß√£o
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main_demo:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
        log_level="info"
    )